{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Stock Prices with Linear Regression\n",
    "\n",
    "## Recap\n",
    "![Alt mindmap](https://s3-eu-west-1.amazonaws.com/gallery-prod-4f50/img/a897779b107f4e8a818316dc40f3d25a.png)\n",
    "[**click here for more details**](https://sketchboard.me/RBiXS3ZIZyOe)\n",
    "\n",
    "## Part 1: Overfitting and Underfitting\n",
    "\n",
    "In this part we are building a polynomial linear regression model and demonstrating the problems of overfitting and underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dataset overfitting_underfitting_dataset.csv\n",
    "data = # Your code here\n",
    "\n",
    "# Show first 5 rows of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot the dataset using plt.scatter()\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "# Your code here\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train/Test split\n",
    "\n",
    "[More in detail](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New technic: train_test_split splits arrays or matrices into random train and test subsets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[['X']], data['Y'], test_size=0.3, random_state=68)\n",
    "# Notice that we use [['X']] and ['Y'] here. Any idea why?\n",
    "\n",
    "# We sort the training set in order to keep the curve-form when we plot it on a graph using plt.plot()\n",
    "X_train = X_train.sort_index()\n",
    "y_train = y_train.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot the training set AND test set on a graph using plt.scatter()\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "# Your code here\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Polynomial Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refer to the example we did on Lecture section, let's build a polynomial linear regression model and train it\n",
    "# Step 1: import LinearRegression and PolynomialFeatures\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature engineering\n",
    "Generate a new feature matrix consisting of all polynomial combinations of the features with degree less than or equal to the specified degree. For example, if an input sample is two dimensional and of the form [a, b], the degree-2 polynomial features are [1, a, b, a^2, ab, b^2].\n",
    "\n",
    "For more information [link](https://stats.stackexchange.com/a/58747)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define a instance of PolynomialFeatures with degree=4 called 'poly_reg'\n",
    "# Your code here\n",
    "\n",
    "\n",
    "# Step 3: Fit and transform 'X_train', 'X_test' with the PolynomialFeatures and save the result in 'X_train_poly' and 'X_test_poly'\n",
    "# Your code here\n",
    "\n",
    "\n",
    "# Step 4: Define a instance of LinearRegression called 'lm'\n",
    "\n",
    "\n",
    "# Step 5: Fitting the Linear Regression Model to the training set (X_train_poly)\n",
    "# Your code here\n",
    "\n",
    "\n",
    "# Step 6: Run predict() on the training set and save the result in 'y_train_predict' in order to plot your model\n",
    "# Your code here\n",
    "\n",
    "\n",
    "# Step 7: Predict test set and save the result in 'y_test_predict'\n",
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now if you did everything correctly this code below should be able to visualize the result\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(X_train, y_train_predict)\n",
    "plt.scatter(X_train, y_train)\n",
    "plt.scatter(X_test, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfitting & Underfitting demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's write a function do the same thing we did in previous step but with degree as a argument\n",
    "def plot_poly_linear_regression(degree=10):\n",
    "    # Your code here\n",
    "    # Hint: copy the code that you did in previous step here \n",
    "    \n",
    "\n",
    "    # calculate the residual errors \n",
    "    train_error = np.sqrt(np.mean(np.square(y_train_predict - y_train)))\n",
    "    test_error = np.sqrt(np.mean(np.square(y_test_predict - y_test)))\n",
    "                          \n",
    "    # Visualization\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.scatter(X_train, y_train, label='Train')\n",
    "    plt.scatter(X_test, y_test, label='Test')\n",
    "    \n",
    "    X_train_2 = np.linspace(X_train.min(), X_train.max(), 100)\n",
    "    plt.plot(X_train_2, lm.predict(poly_reg.fit_transform(X_train_2.reshape(-1, 1))), label='Predict')\n",
    "    plt.title('Train error: {:.3f}\\nTest error: {:.3f}\\n'.format(train_error, test_error))\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code below uses your function above to demo a interative graph which allows us to tune the parameter 'degree'\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = interactive(plot_poly_linear_regression, degree=(1, 20, 1))\n",
    "display(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Part 2: Working on VinGroup's stock prices\n",
    "\n",
    "### Data Description\n",
    "\n",
    "The dataset is about the stock prices of Vingroup from Jan 3rd 2017 to Oct 9th 2018. \n",
    "\n",
    " - **DATE**: Trading date, or trading session.\n",
    " - **OPEN**: Daily opening price, the price of the first trade within each trading day.\n",
    " - **CLOSE**: Daily close price, the price at the end of trading day.\n",
    " - **HIGH**: The highest price at which a stock traded within a day. \n",
    " - **LOW**: The lowest price at which a stock traded within a day.\n",
    " - **VOLUME**: Volume is the number of shares that are traded within a day.\n",
    " - **TICKER**: Security code of Vingroup on the market (VIC).\n",
    " \n",
    "**CLOSE** is our target/dependent variable. We are going to build a model to predict the **Close Price**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import mdates from matplotlib**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need mdates from matplotlib to work with the DATE column\n",
    "import matplotlib.dates as mdates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import stock prices dataset\n",
    "stock = # Your code here\n",
    "\n",
    "# Show first 5 rows of the dataset\n",
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using tail() to show last 5 rows \n",
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check unique values of the column TICKER\n",
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the column **TICKER** contains only one value `VIC` and doesn't give us any information about the **CLOSE** prices. So we will entirely remove the column **TICKER**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using drop() with axis=1 to remove the column TICKER out of our dataset\n",
    "# Your code here\n",
    "\n",
    "\n",
    "stock.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using info() to show overview informations\n",
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DATE** column is considered as `Object`. `Object` is generic data type encapsulates everything from `string` to `integer`, etc. So we need to convert **DATE** to `Datetime` and then using `mdates.data2num()` to convert `Datetime` into `number`. This is because computers process numbers and eventually do math operations on features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and understand this code below. New technic here are the Lambda function and 'apply()'\n",
    "stock['DATE'] = pd.to_datetime(stock['DATE'], format='%d/%m/%Y')\n",
    "stock['DATE2NUM'] = stock['DATE'].apply(lambda x: mdates.date2num(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check again using the function info()\n",
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the new column using the function head()\n",
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how our stock data looks like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code below\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.xticks(rotation=45)\n",
    "plt.plot_date(stock['DATE'], stock['CLOSE'], fmt='b-', xdate=True, ydate=False, label='Real value')\n",
    "plt.ylabel('Close prices')\n",
    "plt.title('Vingroup - VIC')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your job is now to put the code above into a method that we can reuse later on\n",
    "# The method takes the first argument as datatype date (e.g. stock['DATE'])\n",
    "# The second argument should be a vector of close prices (e.g. stock['CLOSE'])\n",
    "# Then the third argument is optional and represents predicted prices of our model\n",
    "# Noted that all of the arguments should have the same length\n",
    "def plot_stock(date, outcome, prediction=None):\n",
    "    # your code here\n",
    "    \n",
    "    return\n",
    "    \n",
    "# The result should be the same graph from the previous step\n",
    "plot_stock(stock['DATE'],stock['CLOSE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the CLOSE column to the variable y\n",
    "# Your code here\n",
    "\n",
    "\n",
    "# Assign ['DATE2NUM'] to the variable X\n",
    "# Your code here\n",
    "\n",
    "\n",
    "# This dataset is called time series dataset. Because the observations (rows) follow each other by the date.\n",
    "# So we can't use train_test_split in this case.\n",
    "# First, we get the number of rows and columns of the dataset\n",
    "nrow , ncol = stock.shape\n",
    "\n",
    "# Then using loc to split the dataset into a training set and a test set\n",
    "X_test = X.loc[:np.floor(nrow*0.3)]\n",
    "X_train = X.loc[np.floor(nrow*0.3):]\n",
    "\n",
    "# Do the same with the outcome y\n",
    "# your code here\n",
    "\n",
    "\n",
    "# To visualize the training set and test set, we need to split the DATE column into 2 parts too\n",
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you do everything correctly your function should be able to plot the training set and test set here\n",
    "# Plot of training set\n",
    "plot_stock(date_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of training set\n",
    "plot_stock(date_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's import Linear Regression from the sci-kit learn library and train your model with X_train, y_train\n",
    "# Notice that we use (date_train, y_train) to plot and (X_train, y_train) to train the model\n",
    "# Your code here\n",
    "\n",
    "\n",
    "# If everything fine, you should be able to print out the coefficients (b1, b2, .. bn) and the intercept (b0)\n",
    "print(lm.coef_)\n",
    "print(lm.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have a Linear Regression model. Let's use function predict() on X_train and save the result in predictions_train\n",
    "# Your code here\n",
    "\n",
    "\n",
    "# Call your plot_stock() function to compare our model's curve with y_train\n",
    "plot_stock(date_train, y_train, predictions_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let see how your model predicts the test set. Save the result in a variable called 'predictions_test'\n",
    "# Your code here\n",
    "\n",
    "\n",
    "# Call your plot_stock() function to compare the result with y_test\n",
    "plot_stock(date_test, y_test, predictions_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not a good result as expected? Do you have any idea why?\n",
    "\n",
    "Let's go back to the splitting data step and add more features to your training set. Let's see how that could improve your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Great job! Hope you enjoy it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
